\section{Optimal STMC}

In this section we present a refinement of algorithm \ref{algorithm:sound-complete} introducing a new property: \textit{optimality}; which in this context optimality refers to not obtaining the same history twice. When extending a history $h$ with an event $e$, if $e$ is either a $\ibegin$ or $\iwrite$ there is no possible redundancy as there can be only one extension, $h \bullet e$. If $e$ is a $\iread$ event, for every $\iwrite$ event $w$ we explore every history $h_w' = h \bullet_w e$. As $h_w'.\wro(e) \neq h_{w'}'.\wro(e)$ if $w \neq w'$, adding a $\iread$ event is no source of redundancy. This is not the case when $e$ is an $\iend$-event and we produce a swap.

%Intuitively, the algorithm \ref{algorithm:sound-complete} is sound, as every history obtained is consistent; but it is also complete, as it explores every possible graph. The latter's proof, however, is not immediate and we will postpone its proof. Nevertheless, assuming those properties are already achieved, we seek for a third one: optimality; which in this context refers to not obtaining the same history twice. Let's analyze every possible scenario to detect where non-optimality may arise. Given a history $h$ and an event $e$, every graph computed by the algorithm as $h' = h \bullet e$ is different, as either $h'$ is unique or the $\wro$ relation differs between two histories. Therefore, the only possible source of redundancy must come from swapping two events. 

\begin{figure}[H]
	
	\centering
	\begin{subfigure}{.3\textwidth}
		\resizebox{\textwidth}{!}{
			\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3cm,
				semithick, transform shape]
				\node[draw, rounded corners=2mm,outer sep=0] (t1) at (-3, 0) {\begin{tabular}{l} $\wrt{x}{0}$ \end{tabular}};
				
				\node[draw, rounded corners=2mm,outer sep=0] (t2) at (-3, -1.5) {\begin{tabular}{l} $\wrt{x}{1}$ \end{tabular}};
				\node[draw, rounded corners=2mm,outer sep=0] (t3) at (0, 0) {\begin{tabular}{l} $a \gets \rd{x}$ \end{tabular}};
				
				\node[draw, rounded corners=2mm,outer sep=0] (t4) at (0, -1.5) {\begin{tabular}{l} $b \gets \rd{x}$ \end{tabular}};
				
				\node[draw, rounded corners=2mm, opacity=0.3] (t5) at (3, -0.75) {\begin{tabular}{l} $\wrt{x}{2}$ \end{tabular}};
				
				
				\path (t1) edge[above] node[yshift=0,xshift=0] {$\wro$} (t3);
				\path (t2) edge[below] node[yshift=-4,xshift=0] {$\wro$} (t4);
			\end{tikzpicture}  
			
		}
		\caption{History a.}
		\label{fig:non_optimality:a}
	\end{subfigure}
	\hspace{.5cm}
	\centering
	\begin{subfigure}{.3\textwidth}
		\resizebox{\textwidth}{!}{
			\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3cm,
				semithick, transform shape]
				\node[draw, rounded corners=2mm,outer sep=0] (t1) at (-3, 0) {\begin{tabular}{l} $\wrt{x}{0}$ \end{tabular}};
				
				\node[draw, rounded corners=2mm,outer sep=0] (t2) at (-3, -1.5) {\begin{tabular}{l} $\wrt{x}{1}$ \end{tabular}};
				\node[draw, rounded corners=2mm,outer sep=0] (t3) at (0, 0) {\begin{tabular}{l} $a \gets \rd{x}$ \end{tabular}};
				
				\node[draw, rounded corners=2mm,outer sep=0] (t4) at (0, -1.5) {\begin{tabular}{l} $b \gets \rd{x}$ \end{tabular}};
				
				\node[draw, rounded corners=2mm, opacity=0.3] (t5) at (3, -0.75) {\begin{tabular}{l} $\wrt{x}{2}$ \end{tabular}};
				
				%\path (t3) edge node {$\so$} (t5);
				%\path (t3) edge node {$\po$} (t3);
				%\path (t1) edge[below] node[yshift=-4,xshift=-4] {$\wro$} (t3_2);
				%\path (t2) edge[below] node[yshift=-4,xshift=4] {$\wro$} (t4_2);
				\path (t1) edge[above] node[yshift=0,xshift=0] {$\wro$} (t3);
				\path (t1) edge[below] node[yshift=-2,xshift=-2] {$\wro$} (t4);
			\end{tikzpicture}  
			
		}
		\caption{History b.}
		\label{fig:non_optimality:b}
	\end{subfigure}
	\hspace{.5cm}
	\centering
	\begin{subfigure}{.3\textwidth}
		\resizebox{\textwidth}{!}{
			\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3cm,
				semithick, transform shape]
				\node[draw, rounded corners=2mm,outer sep=0] (t1) at (-3, 0) {\begin{tabular}{l} $\wrt{x}{0}$ \end{tabular}};
				
				\node[draw, rounded corners=2mm,outer sep=0] (t2) at (-3, -1.5) {\begin{tabular}{l} $\wrt{x}{1}$ \end{tabular}};
				\node[draw, rounded corners=2mm,outer sep=0] (t3) at (0, 0) {\begin{tabular}{l} $a \gets \rd{x}$ \end{tabular}};
				
				\node[draw, rounded corners=2mm,outer sep=0, opacity=0.3] (t4) at (0, -1.5) {\begin{tabular}{l} $b \gets \rd{x}$ \end{tabular}};
				
				\node[draw, rounded corners=2mm] (t5) at (3, -0.75) {\begin{tabular}{l} $\wrt{x}{2}$ \end{tabular}};
				
				
				\path (t5) edge[above] node[yshift=0,xshift=2] {$\wro$} (t3);
				
			\end{tikzpicture}  
			
		}
		\caption{After swap history.}
		\label{fig:non_optimality:c}
	\end{subfigure}
	
	\caption{Two different histories after swapping lead to a common one.}
	\label{fig:non_optimality}
	
\end{figure}

Let's suppose we have a program $\mathcal{P}$ as depicted in figure \ref{fig:non_optimality}, assuming $<_{\ora}$ order transactions as presented from left to right, top to bottom. Given $\mathcal{P}$, algorithm \ref{algorithm:sound-complete} computes the histories \ref{fig:non_optimality:a}, $h$, and \ref{fig:non_optimality:b}, $h'$. After adding the last transaction in both $h,h'$ we produce a swap between $r_a \coloneqq a \gets \rd{x}$ and $w_2 \coloneqq \wrt{x}{2}$; deleting the event $r_b \coloneqq b \gets \rd{x}$ as $\lnot(\tr(r_b) \ [\wro \cup \so]^+ \ \tr(w_2)) $. Therefore, after the swap in both cases we arrive to the history depicted in Figure~\ref{fig:non_optimality:c}; obtaining a non-optimal situation. 

In conclusion, we cannot swap transactions without any limit. As the example in figure \ref{fig:non_optimality} shows, the key of redundancy lies in every $\wro$ edge that is going to be modified: if two histories only differ on those, the resultant history is the same. We define the following concept for controlling this situation:
%described in Figure~\ref{fig:non_optimality}, assuming $\ora$ order transactions as presented from left to right, top to bottom. After adding the last transaction, we can swap it with the first $\iread$ according to $\ora$. As in any case the second one is no $[\wro \cup \so]^+$ related with the last transaction, it has to be deleted to be re-executed at a later point; obtaining in both cases the history depicted in Figure~\ref{fig:non_optimality:c}. Therefore, we have obtained a diamond-like 
%situation where from one state (the empty history) we can reach two other histories, $h$ and $h'$, that lead to a common state. This example expose that the act of swapping cannot be done arbitrarily, and consequently, it is mandatory to establish some protocol to determine when one event can be swapped. 

\begin{definition}
	An event $e$ is \callout{maximally added} in a history $h$ if one of the following condition holds:
	\begin{enumerate}
		\item $e$ is not a $\iread$ event.
		\item $e$ is a non-swapped $\iread$ event that reads the last $\iwrite$ $w$ event before $e$ such that $h.\wro(e) = w$ is consistent.
		\textcolor{red}{TODO: IMA = IsMaximallyAdded (doesnt fit yet (not even with IMA))}
		\begin{equation*}
			\begin{array}{c}

				\textsc{IMA}(h, e) = \exists x \in \mathcal{V}, \exists w \in \writeOp{h} \text{ s.t. } 
				\begin{array}{c}
					w \ [\wro_x] \ e \land 	\isConsistent{h}\\
					\land \\
					\forall w' \in \writeOp{x}, w' <_h e \implies \\
					(w' \leq_h w \lor \lnot \isConsistent{h'}) \\\\
					\left(\text{where } h' = h \land 
					\left\{\begin{array}{cc}
						h'.\wro(e') = h.\wro(e') & \text{if } e' \neq e \\ 
						h'.\wro(e) = w & \text{otherwise} \\ 
					\end{array}\right\}\right)
				\end{array}
			\end{array}
		\end{equation*}
	\end{enumerate}
	\label{def:max_added}
\end{definition}

Intuitively, definition~\ref{def:max_added} allow us to detect when a $\iread$ event $r$ reads from some \textit{default} value, the last $\iwrite$ $w$ event writing $x$ that was added before $r$ and such that the resultant history is consistent. In general, the source of non-optimality comes from the existence of histories differing in some $\wro$-edge involving a transaction that will be deleted. Therefore, we can stablish a simple criterion for guaranteeing optimality: a swap between two events can only happen when every event that have to be re-executed is maximally added. This criterion is defined as function $\protocol$ and it will play the role of $\genericProtocol$ function in our algorithm \ref{algorithm:algo-class}'s instance.

\begin{cframed}[pinegreen]
\begin{equation*}
\begin{array}{ccc}
\protocol(h, r, w) & = & 
	\begin{array}{cccc}
		r \in Del \land \forall e \in Del: \textsc{IsMaximallyAdded}(h, e) \\
		\begin{array}{cccc} 
			\text{where} & Del & = & \{e \ | \ r \leq_h e \land \lnot (\tr(e) \ [\wro \cup \so]^* \ \tr(w))\}\text{}
		\end{array}
	\end{array}
\end{array}
\end{equation*}
\end{cframed}


\begin{algorithm}[H]
	\caption{Optimal recursive STMC}
	\begin{algorithmic}[1]
		
		\makeatletter
		\setcounter{ALG@line}{16}
		\makeatother
		\Statex
		\Statex \ldots
		\Case{$\iend$}
		
		\State $\textsc{STMC}_{rec}(h \bullet a)$
		\ForAll{$w \in \tr(a), x \in \mathcal{V}$ s.t. $\writeVar{w}{x}$}
		\ForAll{$r \in h \text{ s.t. } \readVar{r}{x}$}
		\State $D \gets \{e \ | \ r <_h e \land \lnot (\tr(e) \ [\wro \cup \so]^* \ \tr(a))\}$
		\If{$\forall e \in D \cup \{r\}$: \textsc{IsMaximallyAdded}$(e) $}
		\label{algorithm:IMARec}
		\State $h' \gets (h \setminus D) \bullet a$; $\; h'.\wro[r] \gets w$
		\State $\textsc{STMC}_{rec}(h')$
		\EndIf
		\EndFor
		\EndFor
		\Break
		\EndCase
		\Statex \ldots
	\end{algorithmic}
	\label{algorithm:stmc2}
\end{algorithm}

In algorithm \ref{algorithm:stmc2} is depicted the slight modification needed in \ref{algorithm:sound-complete} for guaranteeing optimality: just adding the condition at line \ref{algorithm:IMARec}, detecting if every deleted event is maximally added, is enough to guarantee optimality.



\textcolor{red}{Add at the end (here) the code of the final algorithm!!!!!}