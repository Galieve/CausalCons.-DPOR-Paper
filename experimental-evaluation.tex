%!TEX root = main.tex
\section{Experimental evaluation}\label{sec:exp}

We evaluate an implementation of $\textsc{explore-ce}$ and $\textsc{explore-ce}^*$ in the context of Java Pathfinder (JPF)~\cite{DBLP:conf/issta/VisserPK04}, a modelchecker for Java concurrent programs. As benchmark, we use bounded-size clients of a number of database-backed applications drawn from the literature of distributed systems and databases.

\subsection{Implementation}

We implemented our algorithms as an extension of the \texttt{DFSearch} class in JPF. For performance reasons, we implemented an iterative version of these algorithms where roughly, inputs to recursive calls are maintained as a collection of histories instead of relying on the call stack. For checking consistency of a history with a given isolation level, we implemented the  algorithms proposed by \citet{DBLP:journals/pacmpl/BiswasE19}. 

%$\textsc{explore-ce}$ and $\textsc{explore-ce}^*$ on top of JPF and an implementation of the algorithms proposed by \citet{DBLP:journals/pacmpl/BiswasE19} for checking consistency of a history with a given isolation level. For performance issues, we implemented an iterative version of these algorithms 

%\ref{algorithm:algo-class} for reducing the actual memory consumption. We employ an annotated stack of database states that is modified in each $\textsc{explore-ce}$ call; and we consider the algorithm works with list instead of simply sets.
%At every step where we execute a $\iread$, we annotate which $\iwrite$ event is reading from and  when the state pops from the stack, we change the $\wro$-dependency. Analogously, at every step we produce a swap, we annotate which tuple given by $\compute$ we used in the swap for selecting a different tuple when the state is popped out.
Our tool takes as input a Java program and isolation levels as parameters. We assume that the program uses a fixed API for interacting with the database which is similar to a key-value store interface. This API consists of specific methods for starting or ending a transaction, reading or writing a global variable. The fixed API is required for being able to maintain the database state separately from the JVM state (the state of the Java program) and update the current history in each database access. This relies on a mechanism for ``transferring'' values read from the database to the JVM state.
% a verification tool for Java concurrent programs. We admit as input a Java program that (1) can be parsed and executed by JPF and (2) employs the API according to the specifications. Our tool is parametric in the isolation levels employed.

%The API provided allow $\ibegin, \iwrite, \iread$ and $\icommit$ operations. Thanks to this API, we can maintain the database state separately from JPF's internal state and update the current history in each database call. We do not rely on any concrete database but store the information as a collection of String, one per write API call executed; along with the $\so$, $\wro$-dependencies between the events associated to them. Any time there is a need to connect data from the local state to the database one or viceversa we copy and store the concrete String value from one state to the other. %Altogether, we are able to simulate from simple variables to actual tables provided the client has proper methods to transform from one to the other representative.

%Our implementation is compatible with JPF's standards, as both algorithm are instances of DFSearch; a JPF for DFS exploring algorithms. Moreover, we built consistency checkers based on the algorithm's presented in \textcolor{red}{Ranadeep and Enea's paper} for different isolation levels to ensure database's soundness. 

%However, for performance issues, we developed an iterative version of the algorithm \ref{algorithm:algo-class} for reducing the actual memory consumption. We employ an annotated stack of database states that is modified in each $\textsc{explore-ce}$ call; and we consider the algorithm works with list instead of simply sets.
%At every step where we execute a $\iread$, we annotate which $\iwrite$ event is reading from and  when the state pops from the stack, we change the $\wro$-dependency. Analogously, at every step we produce a swap, we annotate which tuple given by $\compute$ we used in the swap for selecting a different tuple when the state is popped out. % In addition, as JPF is not designed for supporting database operations, we developed an API that simulates every database instruction. operations, but they have been proved expressive enough both during our experiments and in real time applications. We admit any Java program that (1) can be parsed and executed by JPF and (2) has an equivalent translation into a program written with the syntax defined in Figure~\ref{fig:syntax}.

\subsection{Benchmark}

We consider a set of benchmarks inspired by real-world applications and evaluate them under different types of clients and isolation levels. 
%both implemented following the aforementioned specifications. We provide also examples of different behaviors depending on the isolation level for each applications.

\vspace{1mm}
\noindent
\textit{Shopping Cart~\cite{sivaramakrishnan2015declarative5}} allows users to add, get and remove items from their shopping cart and modify the quantities of the items present in the cart. 
%We employ only one table, $\texttt{cart}$, in this application. Given a program that add an item in one section and deletes it in another one, we may observe, depending on the isolation level, that at the end of the execution the cart contains either zero, one or two items.

\vspace{1mm}
\noindent
\textit{Twitter~\cite{difallah2013oltp}} allows users to follow other users, publish tweets and get their followers, tweets and tweets published by other followers. 
%We model twitter with four tables: $\texttt{users}, \texttt{tweets}, \texttt{followed}, \texttt{followers}$. Under weak isolation levels, it is possible that one user can publish a tweet and not being able to obtain it from a different session. We can also detect other behaviors as users following another users in one session but the latter not being able to find the former as a follower.

\vspace{1mm}
\noindent
\textit{Courseware~\cite{DBLP:conf/esop/NairP020}} manages the enrollment of students in courses in an institution. It allows to open, close and delete courses, enroll students and get all enrollments. One student can only enroll to a course if it is open and its capacity has not reached a fixed limit. 
%It employs three tables, $\texttt{student}, \texttt{course}$ and $\texttt{enrollments}$. Under weak isolation levels, two students in different sessions may enroll to a course with only one free place or being able to enroll into a course that has been deleted in another session.

\vspace{1mm}
\noindent
\textit{Wikipedia~\cite{difallah2013oltp}} allows users to get the content of a page (registered or not), add or remove pages to their watching list and update pages. 
%It employs ten tables, but the vast majority of procedures only access to a small subset of them. Under weak isolation levels, one change in a page may be overwritten by another one done in a different session as well as the watching list may contain a variable number of pages if they are added/deleted from different sessions.

\vspace{1mm}
\noindent
\textit{TPC-C~\cite{TPCC}} models an online shopping application with five types of transactions: reading the stock of a product, creating a new order, getting its status, paying it and delivering it. 
%TPC-C employs nine tables and all its procedures read and write several variables. Under weak isolation level two orders may be created from different sessions or the account balance may be inconsistent if some order is payed twice.

\subsection{Experimental Results}

We designed three experiments where we compare running $\textsc{explore-ce}$ and $\textsc{explore-ce}^*$ for different (combinations of) isolation levels, and we explore the scalability of $\textsc{explore-ce}$ when increasing the number of sessions and transactions per session, respectively. %We did not evaluate the scalability of $\textsc{explore-ce}^*$ since this is a 
We conducted these experiments on an Apple M1 with $8$ cores and $16$ GB of RAM. For each experiment we report running time, memory consumption, and the number of enumerated histories. As the number of histories admitted by a program on a certain isolation level increases, the running time of our algorithms naturally increases as well. 

%We have run three type of experiments to determine the algorithm's scalability. The more transactions that write into the database, the more potential behaviors allowed. Therefore, in each case we design the experiments with this guideline.

\begin{figure}[t]
	\centering
	\begin{subfigure}[t]{0.49\linewidth}
		\centering
		\includegraphics[width=\textwidth]{figures/RA-CC.eps}
		\caption{Execution time for $\textsc{explore-ce}$ under $\CC$ and $\RA$, and $\textsc{explore-ce}^*$ under $\langle\RA, \CC\rangle, \langle\CC, \SI\rangle$ and $\langle\CC, \SER\rangle$. Client programs are ordered according to running time under $\RA$. For the last program, the running time is $25' 17''$ under $\RA$ and $33' 3''$ under $\langle\RA, \CC\rangle$ (out of the figure). The execution time of $\textsc{explore-ce}$ under $\CC$ is indistinguishable from the execution time of $\textsc{explore-ce}^*$ under $\langle\CC, \SI\rangle$ and $\langle\CC, \SER\rangle$.}
		\label{fig:results-ra-cc}
	\end{subfigure}
	\hfill
	\begin{subfigure}[t]{0.49\linewidth}
		\centering
		\includegraphics[width=\textwidth]{figures/Histories.eps}
		\caption{Number of histories per program. For the eight benchmark, we find $12433$ consistent histories under $\RA$, $2309$ under $\CC$ and $1605$ under $\SI$ (out of the figure). \\\\}
		\label{fig:results-histories}
	\end{subfigure}

	\caption{Comparing $\textsc{explore-ce}$ and $\textsc{explore-ce}^*$ under different isolation levels.}
	\label{fig:results1}
\end{figure}

In the first experiment, we consider as benchmark two client programs for each application described above (10 in total), each with 3 sessions and 3 transactions per session. One client has only one writing transaction per session while the second one has two writing transactions per session. 
 %for each application we have designed two programs with three threads each and three transactions per thread; where one contains only one transaction that writes per thread instead of the two writing transactions the second program have (in the case of TPC-C we discriminate transactions depending on the number of variables they write). 
We run $\textsc{explore-ce}$ for these programs under $\CC$ and $\RA$, and $\textsc{explore-ce}^*$ under the pairs of isolation levels $\langle\RA, \CC\rangle$, $\langle\CC, \SI\rangle$ and $\langle\CC, \SER\rangle$. The running times and number of histories are reported in Figure~\ref{fig:results1}. As probably expected, $\textsc{explore-ce}^*$ under $(\RA, \CC)$ has a worse performance than $\textsc{explore-ce}$ under $\CC$ because of the time spent in enumerating histories which are $\RA$ but not $\CC$. As it can be seen in Figure~\ref{fig:results-histories} there is large gap between the number of $\RA$ and $\CC$ histories. The time difference between $\textsc{explore-ce}(I_0)$ and $\textsc{explore-ce}^*(I_0,I)$ is insignificant. This is due to the fact that the consistency checking algorithms of \citet{DBLP:journals/pacmpl/BiswasE19} are polynomial time when the number of sessions is fixed, which makes them fast at least on histories with a small number of sessions.

%However, this is not anymore true for $\textsc{explore-ce}^*$ under $\langle\CC, \SI\rangle$ and $\langle\CC, \SER\rangle$. The difference w.r.t. $\textsc{explore-ce}$ under $\CC$ is insignificant. A possible explanation is that the difference between the number of $\RA$ histories and $\CC$ histories is significantly bigger than the difference between the number of $\CC$ histories and $\SI$/$\SER$ histories.

%number of $\CC$ histories is significantly smaller than $\RA$ histories, the cost of checking consistency with $\SI$ and $\SER$ in $\textsc{explore-ce}^*$ with $\langle\CC, \SI\rangle$ and $\langle\CC, \SER\rangle$. As $\CC$ is a causal-extensible model and it had a reasonable performance under this experiment, in the following we will work only with this isolation level.


%The results obtained in Figure~\ref{fig:results-ra-cc} show that an increment on the number of history a program may have under a concrete isolation level, obliges an increasing execution time. As expected, $\textsc{explore-ce}^*$ under $(\RA, \CC)$ have a worse performance than $\textsc{explore-ce}$ under $\CC$ by the cost of checking if a history satisfies $\CC$. However, as the number of $\CC$ histories is significantly smaller than $\RA$ histories, the cost of $\SI$ and $\SER$ checks is diluted. As $\CC$ is a causal-extensible model and it had a reasonable performance under this experiment, in the following we will work only with this isolation level.
% Moreover, it can be even worse than simply $\textsc{explore-ce}$ under $I_0$ if the $\evaluate$'s cost for isolation level $I$ is higher than the cost of checking if $h$ satisfies $I_0$. Moreover, as seen in Figure~\ref{fig:results-histories}, we notice that even for isolation levels with thousands of histories, the algorithm terminates in a reasonable time (no longer than one hour). As $\CC$ have a reasonable performance under this experiment, in the following we will work only with this isolation level.


% measures the algorithm's performance under $\CC$. We design three types of performance situations depending the number of shared variables a pair of transactions update; being ``Light'' a situation where every update is potentially read by only one thread, ``Heavy'' one where every update writes a variable every transaction reads and ``Medium'' something in between. For each of them, we describe five TPC-C programs, with a different number of threads each, between $1$ and $5$, with only one transaction per thread.

%writing transactions, and make them the same

\begin{figure}[t]
	\centering
	\begin{subfigure}[b]{0.49\linewidth}
		\centering
		\includegraphics[width=\textwidth]{figures/Threads-time.eps}
		\caption{Execution time. For the last ``heavy'' client with 5 sessions, the running time  $20' 40''$ (out of the figure).}
		\label{fig:results-threads}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.49\linewidth}
		\centering
		\includegraphics[width=\textwidth]{figures/Threads-histories.eps}
		\caption{Number of histories. For the last ``heavy'' client with 5 sessions, the number of histories $1296$.}
		\label{fig:results-threads-histories}
	\end{subfigure}
	
	\caption{Evaluating the scalability of $\textsc{explore-ce}(\CC)$ for TPC-C clients when increasing the number of sessions.}
	\label{fig:results2}
\end{figure}

In our second experiment, we investigate the scalability of $\textsc{explore-ce}$ when increasing the number of sessions. We take as benchmark client programs of TPC-C and $\CC$ as isolation level. 
For each $i\in [1,5]$, we consider three clients with $i$ sessions, each containing one transaction, of increasing levels of difficulty that we call light, medium, and heavy. For light clients, each session contains a different type of transaction, so the number of read/write interactions on the same variable is small. All sessions of a heavy client contain the same type of transaction in all sessions, and medium difficulty is an average of these two. The results are reported in Figure~\ref{fig:results2}. As expected, at least for ``heavy'' clients, increasing the number of sessions remains a bottleneck. This is expected also because the size of the output (number of histories) increases significantly as well.
%However, under the small-scope hypothesis, the systematic enumeration of \emph{all} executions of small clients enabled by our algorithms should suffice to uncover all potential bugs in an application. 

%In Figure~\ref{fig:results2} we can observe that, in general, the running time of this algorithm does not exceed the couple of minutes in almost every situation. Moreover, we point that the cost of swapping two events has a sensible impact on the overall performance.

\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{0.49\linewidth}
		\centering
		\includegraphics[width=\textwidth]{figures/Transactions-time.eps}
		\caption{Execution time. For the last two ``heavy'' clients, the running time is $10' 58''$ and $29' 31''$, resp. (out of the figure).}
		\label{fig:results-transactions}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.49\linewidth}
		\centering
		\includegraphics[width=\textwidth]{figures/Transactions-histories.eps}
		\caption{Number of histories. The number of histories for ``medium'' and ``heavy'' clients with $5$ transactions per session is  $420$ and $633$, resp.}
		\label{fig:results-transactions-histories}
	\end{subfigure}
	
	\caption{Evaluating the scalability of $\textsc{explore-ce}(\CC)$ for TPC-C clients when increasing the number of transactions per session.}
	\label{fig:results3}
\end{figure}

For our third experiment, we evaluate the scalability of $\textsc{explore-ce}(\CC)$ when increasing the number of transactions per session. We consider TPC-C clients with 2 sessions and $i$ transactions per session, for  $i\in [1,5]$. As before, we consider clients with increasing levels of difficulty light, medium, and heavy. Figure~\ref{fig:results3} pictures the results. Increasing the number of transactions per session is also a bottleneck which is again partly explained by the increase in the size of the output.
% consists on, fixed the number of threads per program, studying how the algorithm performance when those programs have different number of transactions. Analogously to the previous situation, we design three types of performance situations, ``Heavy'', ``Medium'' and ``Light''; and for each of them, we analyze five TPC-C programs with different number of transactions, from $1$ to $5$.

The memory consumption in all these experiments fluctuates around 300-400 MB, taking into account that JPF forces a minimum consumption of 256MB. There are no remarkable memory consumption variations between different client programs or isolation levels. There are slight grows in memory consumption when the number of histories increases.

%The results in Figure~\ref{fig:results3} supports our claims as the bigger the total space to explore, the greater the time it has to be consumed in the exploration.